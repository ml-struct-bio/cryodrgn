{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# CryoDRGN-ET visualization and analysis\n",
    "\n",
    "This jupyter notebook provides a template for analyzing cryoDRGN-ET results, including:\n",
    "* latent space visualization with PCA/UMAP\n",
    "* clustering\n",
    "* interactive visualization of the latent space, imaging, and pose parameters\n",
    "* interactive selection of particle images from the latent space\n",
    "* interactive generation of volumes from the latent space\n",
    "\n",
    "Note that this is a simple template for data analysis, and not a polished UI. Experience with Python/Pandas is recommended.\n",
    "\n",
    "This notebook assumes that the latent variable dimension is > 1 (e.g. multidimensional plotting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import subprocess\n",
    "import os, sys\n",
    "\n",
    "from cryodrgn import analysis\n",
    "from cryodrgn import utils\n",
    "from cryodrgn import dataset\n",
    "from cryodrgn import ctf\n",
    "from cryodrgn import source\n",
    "import cryodrgn.config\n",
    "from cryodrgn.dataset import TiltSeriesData\n",
    "\n",
    "                \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "from ipywidgets import interact, interactive, HBox, VBox\n",
    "from scipy.spatial.transform import Rotation as RR\n",
    "py.init_notebook_mode()\n",
    "from IPython.display import FileLink, FileLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable interactive widgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Specify the workdir and the epoch number (0-based index) to analyze\n",
    "WORKDIR = '..' \n",
    "EPOCH = None # change me if necessary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.path.abspath(WORKDIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load z\n",
    "with open(f'{WORKDIR}/z.{EPOCH}.pkl','rb') as f:\n",
    "    z = pickle.load(f)\n",
    "    z_logvar = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load UMAP\n",
    "umap = utils.load_pkl(f'{WORKDIR}/analyze.{EPOCH}/umap.pkl')\n",
    "# or run UMAP\n",
    "# umap = analysis.run_umap(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load kmeans\n",
    "KMEANS = None\n",
    "kmeans_labels = utils.load_pkl(f'{WORKDIR}/analyze.{EPOCH}/kmeans{KMEANS}/labels.pkl')\n",
    "kmeans_centers = np.loadtxt(f'{WORKDIR}/analyze.{EPOCH}/kmeans{KMEANS}/centers.txt')\n",
    "# Or re-run kmeans with the desired number of classes\n",
    "#kmeans_labels, kmeans_centers = analysis.cluster_kmeans(z, 20)\n",
    "\n",
    "# Get index for on-data cluster center\n",
    "kmeans_centers, centers_ind = analysis.get_nearest_point(z, kmeans_centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration file\n",
    "config = cryodrgn.config.load(f'{WORKDIR}/config.yaml')\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tilt series data -- Get a representative tilt image for each particle\n",
    "assert config['model_args']['encode_mode'] == 'tilt'\n",
    "p_to_t, t_to_p = TiltSeriesData.parse_particle_tilt(config['dataset_args']['particles'])\n",
    "print(f\"Parsing {config['dataset_args']['particles']}\")\n",
    "print(f\"Detected {len(t_to_p)} tilt images for {len(p_to_t)} particles\")\n",
    "\n",
    "# Selection for the first tilt of each particle\n",
    "first_tilt_ind = np.array([pp[0] for pp in p_to_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load index filter\n",
    "ind_orig = config['dataset_args']['ind']\n",
    "if ind_orig is not None:\n",
    "    print(f\"Loading particle selection from {ind_orig}\")\n",
    "    ind_orig = utils.load_pkl(ind_orig)\n",
    "    ind_orig_tilt = TiltSeriesData.particles_to_tilts(p_to_t, ind_orig)\n",
    "    print(f\"Filtering particles from {len(first_tilt_ind)} to {len(ind_orig)}\")\n",
    "    print(f\"Filtering tilt images from {len(t_to_p)} to {len(ind_orig_tilt)}\")\n",
    "    N_orig_particles = len(p_to_t)\n",
    "    first_tilt_ind = first_tilt_ind[ind_orig]\n",
    "else:\n",
    "    ind_orig_tilt = list(t_to_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load poses\n",
    "if config['dataset_args']['do_pose_sgd']:\n",
    "    pose_pkl = f'{WORKDIR}/pose.{EPOCH}.pkl'\n",
    "    with open(pose_pkl,'rb') as f:\n",
    "        rot, trans = pickle.load(f)\n",
    "else:\n",
    "    pose_pkl = config['dataset_args']['poses']\n",
    "    rot, trans = utils.load_pkl(pose_pkl)\n",
    "    \n",
    "# Convert rotation matrices to euler angles\n",
    "euler = RR.from_matrix(rot).as_euler('zyz', degrees=True)\n",
    "\n",
    "# Filter poses to one representative tilt for each particle\n",
    "rot0 = rot[first_tilt_ind]\n",
    "trans0 = trans[first_tilt_ind]\n",
    "euler0 = euler[first_tilt_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input particles -- only load one tilt image per particle (\"ind0\")\n",
    "particles = source.ImageSource.from_file(config['dataset_args']['particles'],\n",
    "                                         lazy=True,\n",
    "                                         datadir=config['dataset_args']['datadir'],\n",
    "                                         indices=first_tilt_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CTF \n",
    "ctf_params = utils.load_pkl(config['dataset_args']['ctf'])\n",
    "\n",
    "# Filter CTF to one representative tilt for each particle\n",
    "ctf_params = ctf_params[first_tilt_ind]\n",
    "\n",
    "# Print parameters\n",
    "ctf.print_ctf_params(ctf_params[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = analysis.parse_loss(f'{WORKDIR}/run.log')\n",
    "plt.plot(loss)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.axvline(x=EPOCH, linestyle=\"--\", color=\"black\", label=f\"Epoch {EPOCH}\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc, pca = analysis.run_pca(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.jointplot(x=pc[:,0], y=pc[:,1], alpha=.1, s=1)\n",
    "g.set_axis_labels('PC1', 'PC2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    g = sns.jointplot(x=pc[:,0], y=pc[:,1], kind='hex')\n",
    "except ZeroDivisionError:\n",
    "    print(\"Data too small to produce hexbins!\")\n",
    "g.set_axis_labels('PC1', 'PC2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(z.shape[1])+1,pca.explained_variance_ratio_)\n",
    "plt.xticks(np.arange(z.shape[1])+1)\n",
    "plt.xlabel('PC')\n",
    "plt.ylabel('explained variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View pose distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotations\n",
    "analysis.plot_euler(euler[:,0],euler[:,1], euler[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.jointplot(x=umap[:,0], y=umap[:,1], alpha=.1, s=1)\n",
    "g.set_axis_labels('UMAP1', 'UMAP2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    g = sns.jointplot(x=umap[:,0], y=umap[:,1], kind='hex')\n",
    "except ZeroDivisionError:\n",
    "    print(\"Data too small to produce hexbins!\")\n",
    "g.set_axis_labels('UMAP1', 'UMAP2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View K-means clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = len(set(kmeans_labels))\n",
    "c = pca.transform(kmeans_centers) # transform to view with PCs\n",
    "analysis.plot_by_cluster(pc[:,0], pc[:,1], K, \n",
    "                         kmeans_labels, \n",
    "                         centers=c,\n",
    "                         annotate=True)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = analysis.plot_by_cluster_subplot(pc[:,0], pc[:,1], K, \n",
    "                            kmeans_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.plot_by_cluster(umap[:,0], umap[:,1], K, \n",
    "                         kmeans_labels, \n",
    "                         centers_ind=centers_ind,\n",
    "                         annotate=True)\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = analysis.plot_by_cluster_subplot(umap[:,0], umap[:,1], K, \n",
    "                            kmeans_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive visualization\n",
    "\n",
    "Interactive visualization of the latent encodings for the trained model. Each point represents a particle image of the dataset. The hover text includes the index of the image in the particle stack. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into a pandas dataframe\n",
    "df = analysis.load_dataframe(z=z, \n",
    "                             pc=pc, \n",
    "                             euler=euler0, \n",
    "                             trans=trans0, \n",
    "                             labels=kmeans_labels, \n",
    "                             umap=umap,\n",
    "                             df1=ctf_params[:,2],\n",
    "                             df2=ctf_params[:,3],\n",
    "                             dfang=ctf_params[:,4],\n",
    "                             phase=ctf_params[:,8])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotated points correspond to kmeans cluster centers\n",
    "widget, fig = analysis.ipy_plot_interactive_annotate(df,centers_ind)\n",
    "VBox((widget,fig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive selection\n",
    "\n",
    "The next two cells contain helper code to select particles using an interactive lasso tool. \n",
    "\n",
    "1. In the first cell, select points with the lasso tool. The table widget is dynamically updated with the most recent selection's indices. \n",
    "2. Then once you've finalized your selection, use the next cell to save the particle indices for downstream analysis/viz.\n",
    "\n",
    "(Double click to clear selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget, fig, ind_table = analysis.ipy_plot_interactive(df)\n",
    "VBox((widget,fig,ind_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_selected = ind_table.data[0].cells.values[0] # save table values\n",
    "ind_selected = np.array(ind_selected)\n",
    "ind_selected_not = np.array(sorted(set(np.arange(len(df))) - set(ind_selected)))\n",
    "\n",
    "print('Selected indices:')\n",
    "print(ind_selected)\n",
    "print('Number of selected points:')\n",
    "print(len(ind_selected))\n",
    "print('Number of unselected points:')\n",
    "print(len(ind_selected_not))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize selected subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View PCA\n",
    "plt.scatter(pc[:,0], pc[:,1], alpha=.1, s=1)\n",
    "plt.scatter(pc[ind_selected,0], pc[ind_selected,1], alpha=.1, s=1)\n",
    "plt.xlabel('PC1 ({:.2f})'.format(pca.explained_variance_ratio_[0]))\n",
    "plt.ylabel('PC2 ({:.2f})'.format(pca.explained_variance_ratio_[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View umap\n",
    "plt.scatter(umap[:,0], umap[:,1], alpha=.1, s=1)\n",
    "plt.scatter(umap[ind_selected,0], umap[ind_selected,1], alpha=.1, s=1)\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset of dataframe\n",
    "df_sub = df.loc[ind_selected]\n",
    "df_sub_not = df.loc[ind_selected_not]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# View pose distribution\n",
    "if df_sub.shape[0] >= 10:\n",
    "    analysis.plot_euler(df_sub.theta, df_sub.phi, df_sub.psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget, fig, ind_table = analysis.ipy_plot_interactive(df_sub)\n",
    "VBox((widget,fig,ind_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the index selection\n",
    "\n",
    "The indices for the selected particles may be saved for use in downstream processing in cryoDRGN or with other tools.\n",
    "Within cryoDRGN, selections are saved a numpy array in `.pkl` file format. Then, the selected indices can be\n",
    "provided to cryoDRGN with the `--ind` argument to train a new model on a subset of the images. \n",
    "\n",
    "Tools are provided in the `utils` subdirectory of the cryoDRGN repo to help convert the index selection to\n",
    "`.star` file format.\n",
    "\n",
    "**NOTE:** If there are multiple rounds of index filtering performed on the same particle stack (i.e. your results\n",
    "come from a training run that already uses an --ind subselection), the index selection must be converted into the\n",
    "correct indices into the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_file = os.path.join(\n",
    "    WORKDIR, f\"analyze.{EPOCH}\", \"tmp_ind_selected.pkl\") # RENAME ME\n",
    "\n",
    "### IMPORTANT: convert index selection to original particles indices if current results\n",
    "# have already been filtered\n",
    "\n",
    "if ind_orig is not None:\n",
    "    ind_selected_orig = analysis.convert_original_indices(\n",
    "        ind_selected, N_orig_particles, ind_orig)\n",
    "    utils.save_pkl(ind_selected_orig, indices_file)\n",
    "else:\n",
    "    utils.save_pkl(ind_selected, indices_file)\n",
    "\n",
    "print(f\"Saved chosen indices to {os.path.abspath(indices_file)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View particles\n",
    "\n",
    "View images at selected points in latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_ind = ind_selected # or set to custom selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose 25 particles to view at random\n",
    "if len(particle_ind) > 25:\n",
    "    ind_subset25 = np.random.choice(particle_ind, 25, replace=False)\n",
    "else: \n",
    "    ind_subset25 = particle_ind\n",
    "print(ind_subset25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [particles[int(ii)][0] for ii in ind_subset25]\n",
    "analysis.plot_projections(p)\n",
    "widget, fig = analysis.ipy_plot_interactive_annotate(df, ind_subset25, opacity=.1)\n",
    "VBox((widget,fig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate volumes\n",
    "\n",
    "Generate volumes at selected points in latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_ind = [] # ADD INDICES HERE\n",
    "print(vol_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget, fig = analysis.ipy_plot_interactive_annotate(df, vol_ind, opacity=.1)\n",
    "VBox((widget,fig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outdir():\n",
    "    '''Helper function to get a clean directory to save volumes'''\n",
    "    for i in range(100000):\n",
    "        outdir = f'reconstruct_{i:06d}'\n",
    "        if os.path.exists(outdir): continue\n",
    "        else: break\n",
    "    return outdir\n",
    "\n",
    "def generate_volumes(zvalues, outdir, **kwargs):\n",
    "    '''Helper function to call cryodrgn eval_vol and generate new volumes'''\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    np.savetxt(f'{outdir}/zfile.txt', zvalues)\n",
    "    analysis.gen_volumes(f'{WORKDIR}/weights.{EPOCH}.pkl',\n",
    "                         f'{WORKDIR}/config.yaml',\n",
    "                         f'{outdir}/zfile.txt',\n",
    "                         f'{outdir}', **kwargs)\n",
    "    return FileLinks(f'{outdir}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a unique output directory, or define your own\n",
    "outdir = get_outdir()\n",
    "print(os.path.abspath(outdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify any defaults for volume generation -- see `cryodrgn eval_vol -h` for details \n",
    "Apix = 1 # Set to volume pixel size\n",
    "flip = False # Hand flip?\n",
    "invert = False # Invert contrast?\n",
    "downsample = None # Set to smaller box size if desired\n",
    "\n",
    "generate_volumes(z[vol_ind], outdir, Apix=Apix, flip=flip, downsample=downsample, invert=invert)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
