# CryoDRGN Test Coverage Analysis Report
==================================================

## Test Suite Statistics
ğŸ“ Total test files: 35
ğŸ§ª Total test functions: 163
ğŸ“Š Parametrized tests: 222
ğŸ—ï¸ Class-based tests: 23
ğŸš€ Training tests: 9
ğŸ’¾ File I/O tests: 24

## Test Organization Metrics
ğŸ“ˆ Average tests per file: 4.7
ğŸ¯ Parametrization ratio: 136.2%

## Potential Coverage Gaps
âš ï¸ Modules without dedicated tests (44 total):
   - _version
   - abinit_het
   - abinit_homo
   - analysis
   - analyze
   - analyze_convergence
   - analyze_landscape
   - analyze_landscape_full
   - backproject_voxel
   - beta_schedule
   ... and 34 more

## Improvement Suggestions
- ğŸ” Add tests for untested modules: _version, abinit_het, abinit_homo, analysis, analyze
- âš¡ Consider optimizing 9 training tests with session-scoped fixtures
- ğŸ“Š High number of parametrized tests - consider reducing combinations for faster execution

## Parallelization Opportunities
- Fast unit tests: FFT, utils, source operations
- Medium tests: Parsing, file I/O, data processing
- Heavy tests: Training, reconstruction, integration

## Recommended Test Execution Strategy
```bash
# Phase 1: Fast tests (high parallelization)
pytest tests/test_utils.py tests/test_fft.py tests/test_source.py -n4 --dist=each

# Phase 2: Medium tests (moderate parallelization)
pytest tests/test_parse.py tests/test_relion.py tests/test_writestar.py -n3 --dist=loadscope

# Phase 3: Heavy tests (conservative parallelization)
pytest tests/test_integration.py tests/test_reconstruct_*.py -n2 --dist=loadgroup
```